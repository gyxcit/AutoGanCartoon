{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, ReLU, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de TensorFlow : 2.18.0\n",
      "GPU disponible : []\n"
     ]
    }
   ],
   "source": [
    "print(\"Version de TensorFlow :\", tf.__version__)\n",
    "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load and resize an image to the target size.\n",
    "    \"\"\"\n",
    "    image = Image.open(file_path).convert('RGB')\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype('float32') / 127.5 - 1  # Normalize to [-1, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(input_dir, target_dir, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load and resize datasets from input and target directories.\n",
    "    \"\"\"\n",
    "    input_images = sorted(glob.glob(f\"{input_dir}/*.jpg\"))\n",
    "    target_images = sorted(glob.glob(f\"{target_dir}/*.jpg\"))\n",
    "\n",
    "    input_data = [load_image(img, target_size) for img in input_images]\n",
    "    target_data = [load_image(img, target_size) for img in target_images]\n",
    "\n",
    "    min_size = min(len(input_data), len(target_data))\n",
    "    return np.array(input_data[:min_size]), np.array(target_data[:min_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_align_datasets(input_dir, target_dir, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Charge les images des répertoires spécifiés, les redimensionne et les aligne pour avoir le même nombre d'images.\n",
    "    \n",
    "    :param input_dir: Répertoire contenant les images normales.\n",
    "    :param target_dir: Répertoire contenant les images cartoonisées.\n",
    "    :param target_size: Taille cible pour le redimensionnement.\n",
    "    :return: Deux listes numpy contenant les images alignées.\n",
    "    \"\"\"\n",
    "    # Charger les chemins des fichiers\n",
    "    input_images = sorted(glob.glob(os.path.join(input_dir, '*.jpg')))\n",
    "    target_images = sorted(glob.glob(os.path.join(target_dir, '*.jpg')))\n",
    "    \n",
    "    # S'assurer que les deux ensembles ont le même nombre d'images\n",
    "    min_size = min(len(input_images), len(target_images))\n",
    "    input_images = input_images[:min_size]\n",
    "    target_images = target_images[:min_size]\n",
    "\n",
    "    # Charger et redimensionner les images\n",
    "    input_data = [load_image(img, target_size) for img in input_images]\n",
    "    target_data = [load_image(img, target_size) for img in target_images]\n",
    "    \n",
    "    return np.array(input_data), np.array(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    inputs = Input(shape=[256, 256, 3])\n",
    "\n",
    "    # Encoder\n",
    "    down1 = Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
    "    down1 = LeakyReLU(0.2)(down1)\n",
    "\n",
    "    down2 = Conv2D(128, 4, strides=2, padding='same')(down1)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = LeakyReLU(0.2)(down2)\n",
    "\n",
    "    down3 = Conv2D(256, 4, strides=2, padding='same')(down2)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = LeakyReLU(0.2)(down3)\n",
    "\n",
    "    # Decoder\n",
    "    up1 = Conv2DTranspose(128, 4, strides=2, padding='same')(down3)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = ReLU()(up1)\n",
    "    up1 = Concatenate()([up1, down2])\n",
    "\n",
    "    up2 = Conv2DTranspose(64, 4, strides=2, padding='same')(up1)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = ReLU()(up2)\n",
    "    up2 = Concatenate()([up2, down1])\n",
    "\n",
    "    outputs = Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(up2)\n",
    "\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Model\n",
    "def build_discriminator():\n",
    "    input_image = Input(shape=[256, 256, 3])\n",
    "    target_image = Input(shape=[256, 256, 3])\n",
    "\n",
    "    x = Concatenate()([input_image, target_image])\n",
    "    #64\n",
    "    x = Conv2D(64, 4, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    #128\n",
    "    x = Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    #256\n",
    "    x = Conv2D(256, 4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    #512\n",
    "    x = Conv2D(512, 4, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # patch output\n",
    "    x = Conv2D(1, 4, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    # define model\n",
    "    return Model([input_image, target_image], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "def adversarial_loss(disc_generated_output):\n",
    "    return tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(disc_generated_output), disc_generated_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(gen_output, target):\n",
    "    return tf.reduce_mean(tf.abs(target - gen_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target, lambda_l1=100):\n",
    "    adv_loss = adversarial_loss(disc_generated_output)\n",
    "    l1 = l1_loss(gen_output, target)\n",
    "    return adv_loss + lambda_l1 * l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output))\n",
    "    fake_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output))\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target_image, generator, discriminator, gen_optimizer, disc_optimizer, lambda_l1=100):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        # Discriminator outputs\n",
    "        real_output = discriminator([input_image, target_image], training=True)\n",
    "        fake_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        # Compute losses\n",
    "        gen_loss = generator_loss(fake_output, gen_output, target_image, lambda_l1)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Compute gradients\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply gradients (ensure these optimizers are initialized outside the function)\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, generator, discriminator, gen_optimizer, disc_optimizer, epochs=10):\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for input_image, target_image in dataset:\n",
    "            gen_loss, disc_loss = train_step(input_image, target_image, generator, discriminator, gen_optimizer, disc_optimizer)\n",
    "            print(f\"Step Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}\")  # Débogage des pertes\n",
    "            epoch_gen_loss.append(gen_loss.numpy())\n",
    "            epoch_disc_loss.append(disc_loss.numpy())\n",
    "\n",
    "        gen_losses.append(np.mean(epoch_gen_loss))\n",
    "        disc_losses.append(np.mean(epoch_disc_loss))\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Gen Loss = {gen_losses[-1]:.4f}, Disc Loss = {disc_losses[-1]:.4f}\")\n",
    "\n",
    "    # Vérification des données avant tracé\n",
    "    if not gen_losses or not disc_losses:\n",
    "        print(\"Erreur : Les pertes sont vides. Vérifiez les étapes de calcul.\")\n",
    "        return\n",
    "\n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(gen_losses, label=\"Generator Loss\")\n",
    "    plt.plot(disc_losses, label=\"Discriminator Loss\")\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"learning_curves.png\")  # Sauvegarde les courbes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to new images\n",
    "def cartoonify_image(generator, image_path, target_size=(256, 256)):\n",
    "    input_image = load_image(image_path, target_size)\n",
    "    generated_image = generator(input_image[tf.newaxis, ...], training=False)\n",
    "    generated_image = ((generated_image.numpy().squeeze() + 1) / 2 * 255).astype('uint8')\n",
    "    return Image.fromarray(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "input_dir = \"dataset/normal\"\n",
    "target_dir = \"dataset/cartoon\"\n",
    "\n",
    "input_images, target_images = load_and_align_datasets(input_dir, target_dir, target_size=(256, 256))\n",
    "\n",
    "# Split into train and test sets\n",
    "input_train, input_test, target_train, target_test = train_test_split(\n",
    "    input_images, target_images, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(1000).batch(8)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((input_test, target_test)).batch(8)\n",
    "\n",
    "# Build models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Optimizers\n",
    "gen_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "disc_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "# Train\n",
    "train(train_dataset, \n",
    "    generator, \n",
    "    discriminator, \n",
    "    gen_optimizer, \n",
    "    disc_optimizer, \n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate on the test set (Optional)\n",
    "print(\"Evaluating on test dataset...\")\n",
    "for input_image, target_image in test_dataset:\n",
    "    generated_image = generator(input_image, training=False)\n",
    "    # Add evaluation metrics here (e.g., SSIM, PSNR, etc.)\n",
    "\n",
    "# Save the models\n",
    "generator.save(\"generator_model.h5\")\n",
    "discriminator.save(\"discriminator_model.h5\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def resize_image(input_path, output_path, size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Redimensionne une image au format spécifié et l'enregistre à l'emplacement choisi.\n",
    "\n",
    "    :param input_path: Chemin de l'image d'entrée.\n",
    "    :param output_path: Chemin de sauvegarde pour l'image redimensionnée.\n",
    "    :param size: Taille cible sous la forme (largeur, hauteur).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ouvrir l'image\n",
    "        with Image.open(input_path) as img:\n",
    "            # Redimensionner l'image\n",
    "            resized_img = img.resize(size, Image.ANTIALIAS)\n",
    "            # Sauvegarder l'image redimensionnée\n",
    "            resized_img.save(output_path)\n",
    "            print(f\"L'image a été redimensionnée et sauvegardée dans {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de l'image : {e}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "resize_image(\"chemin/vers/image.jpg\", \"chemin/vers/image_redimensionnee.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a new image\n",
    "test_image_path = \"test_gen/68.jpg\"\n",
    "result_image = cartoonify_image(generator, test_image_path)\n",
    "result_image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
